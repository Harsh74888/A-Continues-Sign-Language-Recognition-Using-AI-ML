This project implements a Continuous Sign Language Recognition system using a hybrid Convolutional Neural Network (CNN) for spatial feature extraction and a Bidirectional LSTM (BiLSTM) for temporal sequence modeling.
The goal is to help bridge communication barriers for deaf and mute individuals by recognizing sign language sequences from video frames
